{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d89b5c",
   "metadata": {},
   "source": [
    "# Random Forest from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a2a63",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9ae66",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe90a25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Information Gain and Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a2c86",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Building the Tree and Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd8127",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pruning and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fecaa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10145329",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Forest as an Ensemble of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33faaaff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Subspace Method for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd31149",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bootstrapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b6a96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff4dea",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation of Models and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b325d0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variations and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54db96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Feature Importance Estimation with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17373fa2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Handling Missing Data and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edb49c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extending Random Forest to Handle Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45514f56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Multiclass Classification and Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f75f0c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Coursework for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ecda3b4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_dim=None, split_point=None, label=None):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_point = split_point\n",
    "        self.label = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.label is not None\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        \n",
    "    # my own created definition that will compute the information (or entropy) \n",
    "    def compute_info(self, labels: List[int]) -> float:\n",
    "  \n",
    "        total_samples = len(labels)\n",
    "        label_counts = {}\n",
    "        info = 0.0\n",
    "\n",
    "        for label in labels:\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "\n",
    "        for count in label_counts.values():\n",
    "            probability = count / total_samples\n",
    "            # this is the key line: information is the negative sum of the probablity of each class times the log of\n",
    "            # that same probablity value for each class\n",
    "            info -= probability * math.log2(probability)\n",
    "\n",
    "        return info\n",
    "    \n",
    "    def split_info(self, data: List[List[float]], label: List[int], split_dim: int, split_point: float) -> float:\n",
    "        \n",
    "        # left and right just represent the two subsets that are created when we split the data. We can capture the \n",
    "        # data that is in each subset, as well as the labels\n",
    "        data_left = []\n",
    "        data_right = []\n",
    "        label_left = []\n",
    "        label_right = []\n",
    "        \n",
    "        # now we iterate through each value of the given dimension (split_dim) and check if it is greater than or equal to\n",
    "        # the split_point. Depending on the result, it goes to the left subset or right subset\n",
    "        for i in range(len(data)):\n",
    "            if data[i][split_dim] <= split_point:\n",
    "                data_left.append(data[i])\n",
    "                label_left.append(label[i])\n",
    "            else:\n",
    "                data_right.append(data[i])\n",
    "                label_right.append(label[i])\n",
    "\n",
    "        total_samples = len(data)\n",
    "        total_left = len(data_left)\n",
    "        total_right = len(data_right)\n",
    "\n",
    "        p_left = total_left / total_samples\n",
    "        p_right = total_right / total_samples\n",
    "        \n",
    "        # we then weigh the information we gather from each side's split, and return the sum of those as info_a\n",
    "        info_left = self.compute_info(label_left)\n",
    "        info_right = self.compute_info(label_right)\n",
    "        info_a = p_left * info_left + p_right * info_right\n",
    "\n",
    "        return info_a\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "    def fit(self, train_data: List[List[float]], train_label: List[int]) -> None:\n",
    "        self.root = self._recursive_build(train_data, train_label)\n",
    "\n",
    "    def _recursive_build(self, data: List[List[float]], labels: List[int], depth: int = 1) -> Node:\n",
    "        \n",
    "        # get the majority class of this current subset incase we need to know\n",
    "        label_counts = Counter(labels)\n",
    "        sorted_labels = sorted(label_counts.items(), key=lambda x: (-x[1], x[0]))\n",
    "        majority_label = sorted_labels[0][0]\n",
    "        \n",
    "        # sort of stopping criteria - if all of the data in the current subset is the same, no more splits are needed\n",
    "        if len(set(labels)) == 1 or depth > 2:\n",
    "            return Node(label=majority_label,split_dim=-1, split_point=-1.0)\n",
    "        \n",
    "        # grabs the number of features or attributes\n",
    "        num_features = len(data[0])\n",
    "        # initializes the best_info_gain to negative infinity\n",
    "        best_info_gain = float('-inf')\n",
    "        # initializes the best split dimension to -1\n",
    "        best_split_dim = -1\n",
    "        # sets the best split point at -1 to start\n",
    "        best_split_point = -1\n",
    "        \n",
    "        # for each feature in all features...\n",
    "        for split_dim in range(num_features):\n",
    "            # get split points between all attributes of this subset\n",
    "            split_points = self._calculate_split_points(data, split_dim)\n",
    "            \n",
    "            # check info gain and find best info gain\n",
    "            for split_point in split_points:\n",
    "                info_gain = self._calculate_info_gain(data, labels, split_dim, split_point)\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_split_dim = split_dim\n",
    "                    best_split_point = split_point\n",
    "                    \n",
    "        node = Node(split_dim=best_split_dim, split_point=best_split_point,label=majority_label)\n",
    "\n",
    "        data_left, labels_left, data_right, labels_right = self._split_data(data, labels, best_split_dim, best_split_point)\n",
    "        if data_left and data_right:\n",
    "            node.left = self._recursive_build(data_left, labels_left,depth = depth + 1)\n",
    "            node.right = self._recursive_build(data_right, labels_right, depth = depth + 1)\n",
    "            \n",
    "        return node\n",
    "   \n",
    "    def _split_data(self, data: List[List[float]], labels: List[int], split_dim: int, split_point: float) -> Tuple[List[List[float]], List[int], List[List[float]], List[int]]:\n",
    "        data_left, labels_left, data_right, labels_right = [], [], [], []\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if data[i][split_dim] <= split_point:\n",
    "                data_left.append(data[i])\n",
    "                labels_left.append(labels[i])\n",
    "            else:\n",
    "                data_right.append(data[i])\n",
    "                labels_right.append(labels[i])\n",
    "\n",
    "        return data_left, labels_left, data_right, labels_right\n",
    "\n",
    "    def _calculate_info_gain(self, data: List[List[float]], labels: List[int], split_dim: int, split_point: float) -> float:\n",
    "        total_samples = len(data)\n",
    "        total_left, total_right = 0, 0\n",
    "        count_left, count_right = {}, {}\n",
    "\n",
    "        for i in range(total_samples):\n",
    "            if data[i][split_dim] <= split_point:\n",
    "                total_left += 1\n",
    "                label = labels[i]\n",
    "                if label in count_left:\n",
    "                    count_left[label] += 1\n",
    "                else:\n",
    "                    count_left[label] = 1\n",
    "            else:\n",
    "                total_right += 1\n",
    "                label = labels[i]\n",
    "                if label in count_right:\n",
    "                    count_right[label] += 1\n",
    "                else:\n",
    "                    count_right[label] = 1\n",
    "\n",
    "        info = self.compute_info(labels)\n",
    "        info_left = 0.0\n",
    "        info_right = 0.0\n",
    "\n",
    "        for count in count_left.values():\n",
    "            probability = count / total_left\n",
    "            info_left -= probability * math.log2(probability)\n",
    "\n",
    "        for count in count_right.values():\n",
    "            probability = count / total_right\n",
    "            info_right -= probability * math.log2(probability)\n",
    "\n",
    "        info_gain = info - ((total_left / total_samples) * info_left + (total_right / total_samples) * info_right)\n",
    "        return info_gain\n",
    "    \n",
    "    def _calculate_split_points(self, data: List[List[float]], split_dim: int) -> List[float]:\n",
    "        attribute_values = sorted([data_point[split_dim] for data_point in data])\n",
    "        split_points = [(attribute_values[i] + attribute_values[i + 1]) / 2 for i in range(len(attribute_values) - 1)]\n",
    "        return split_points\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "    def classify(self, train_data: List[List[float]], train_label: List[int], test_data: List[List[float]]) -> List[int]:\n",
    "        self.fit(train_data, train_label)\n",
    "        predictions = []\n",
    "\n",
    "        for data_point in test_data:\n",
    "            predicted_label = self._traverse_tree(data_point, self.root)\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def _traverse_tree(self, data_point: List[float], node: Node) -> int:\n",
    "        if node.left is None and node.right is None:\n",
    "            return node.label\n",
    "        if data_point[node.split_dim] <= node.split_point:\n",
    "            return self._traverse_tree(data_point, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(data_point, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c5096242",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2452987659940624\n"
     ]
    }
   ],
   "source": [
    "# Split Info Test\n",
    "\n",
    "def parse_input_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        split_dim = int(file.readline().strip())\n",
    "        split_point = float(file.readline().strip())\n",
    "        data = []\n",
    "        labels = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            parts = line.split()\n",
    "            label = int(parts[0])\n",
    "            attributes = [float(attr.split(':')[1]) for attr in parts[1:]]\n",
    "            data.append(attributes)\n",
    "            labels.append(label)\n",
    "    return data, labels, split_dim, split_point\n",
    "\n",
    "input_file = r\"C:\\Users\\rogerree\\Downloads\\01mSTLanT0igEUUS8kDmDQ_2834ea673e8949dea706a3da771f23f1_PA-DT-Handout\\dt_handout\\sample_test_cases\\split_info\\input01.txt\"\n",
    "data, labels, split_dim, split_point = parse_input_file(input_file)\n",
    "\n",
    "solution = Solution()\n",
    "\n",
    "\n",
    "# Call the split_info method with the parsed data\n",
    "result = solution.split_info(data, labels, split_dim, split_point)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8f93691e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{split_dim: 1, split_point: 2.076767332959929, label: 3}{{split_dim: 2, split_point: 2.0413842935532105, label: 2}{{split_dim: -1, split_point: -1.0, label: 2}}{{split_dim: -1, split_point: -1.0, label: 2}}}{{split_dim: 2, split_point: 3.041219385179334, label: 3}{{split_dim: -1, split_point: -1.0, label: 3}}{{split_dim: -1, split_point: -1.0, label: 2}}}\n",
      "\n",
      "{{{split_dim: -1, split_point: -1.0, label: 2}}{split_dim: 2, split_point: 2.0413842935532105, label: 2}{{split_dim: -1, split_point: -1.0, label: 2}}}{split_dim: 1, split_point: 2.076767332959929, label: 3}{{{split_dim: -1, split_point: -1.0, label: 3}}{split_dim: 2, split_point: 3.041219385179334, label: 3}{{split_dim: -1, split_point: -1.0, label: 2}}}\n"
     ]
    }
   ],
   "source": [
    "# Tree Structure Test\n",
    "\n",
    "filename = r\"C:\\Users\\rogerree\\Downloads\\01mSTLanT0igEUUS8kDmDQ_2834ea673e8949dea706a3da771f23f1_PA-DT-Handout\\dt_handout\\sample_test_cases\\tree_structure\\input01.txt\"\n",
    "\n",
    "# Read the input file and extract dataset and labels\n",
    "def read_input_file(file_path):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip().split()\n",
    "            labels.append(int(line[0]))\n",
    "            data_point = [float(entry.split(':')[1]) for entry in line[1:]]\n",
    "            dataset.append(data_point)\n",
    "    return dataset, labels\n",
    "\n",
    "def preorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + preorder_traversal(node.left) + \"}\"\n",
    "        result += \"{\" + preorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "def inorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.left) + \"}\"\n",
    "    result += \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "# File path of the input file\n",
    "input_file = filename\n",
    "\n",
    "# Read the input file to extract dataset and labels\n",
    "dataset, labels = read_input_file(input_file)\n",
    "\n",
    "# Create an instance of the Solution class\n",
    "solution = Solution()\n",
    "\n",
    "# Build the decision tree using the fit function\n",
    "solution.fit(dataset, labels)\n",
    "\n",
    "# Perform preorder traversal on the decision tree\n",
    "preorder_result = preorder_traversal(solution.root)\n",
    "print(preorder_result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Perform inorder traversal on the decision tree\n",
    "inorder_result = inorder_traversal(solution.root)\n",
    "print(inorder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b952ac0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Classification Test\n",
    "\n",
    "def parse_classification_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        test_data = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            parts = line.split()\n",
    "            label = int(parts[0])\n",
    "            attributes = [float(attr.split(':')[1]) for attr in parts[1:]]\n",
    "            \n",
    "            if label != -1:\n",
    "                train_data.append(attributes)\n",
    "                train_label.append(label)\n",
    "            else:\n",
    "                test_data.append(attributes)\n",
    "    \n",
    "    return train_data, train_label, test_data\n",
    "\n",
    "input_file = r\"C:\\Users\\rogerree\\Downloads\\01mSTLanT0igEUUS8kDmDQ_2834ea673e8949dea706a3da771f23f1_PA-DT-Handout\\dt_handout\\sample_test_cases\\classification\\input01.txt\"\n",
    "train_data, train_label, test_data = parse_classification_data(input_file)\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "solution = Solution()\n",
    "\n",
    "\n",
    "# Call the classify method with the extracted data\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e653bba",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c828c4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n"
     ]
    }
   ],
   "source": [
    "print(\"yo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b30f7a7eb703ca28cacee6ec948cc633c111373f841ced60a7b8e477f4c2a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
