{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d89b5c",
   "metadata": {},
   "source": [
    "# Random Forest from Scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d944ef2",
   "metadata": {},
   "source": [
    "In this notebook, I will be entirely covering topics relating to the Random Forest Algorithm. This will start with a simple decision tree implementation, and go over various topics. The dataset that will be used is a NASA star type classfication dataset, where the goal is to have our tree predict the correct star classification given its tree of rules. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd7a2a63",
   "metadata": {},
   "source": [
    "## Importing and Prepping Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59c2054b",
   "metadata": {},
   "source": [
    "Temperature -- K <br>\n",
    "L -- L/Lo<br>\n",
    "R -- R/Ro<br>\n",
    "AM -- Mv<br>\n",
    "Color -- General Color of Spectrum<br>\n",
    "Spectral_Class -- O,B,A,F,G,K,M / SMASS - https://en.wikipedia.org/wiki/Asteroid_spectral_types<br>\n",
    "Type -- Red Dwarf, Brown Dwarf, White Dwarf, Main Sequence , Super Giants, Hyper Giants<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "978a9db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\rogerree\\\\OneDrive - Merck Sharp & Dohme LLC\\\\Documents\\\\Personal Projects\\\\Data\\\\Stars.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "156961ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temperature         int64\n",
       "L                 float64\n",
       "R                 float64\n",
       "A_M               float64\n",
       "Color              object\n",
       "Spectral_Class     object\n",
       "Type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23ca242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spectral_Class</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature         L       R    A_M Color Spectral_Class  Type\n",
       "0         3068  0.002400  0.1700  16.12   Red              M     0\n",
       "1         3042  0.000500  0.1542  16.60   Red              M     0\n",
       "2         2600  0.000300  0.1020  18.70   Red              M     0\n",
       "3         2800  0.000200  0.1600  16.65   Red              M     0\n",
       "4         1939  0.000138  0.1030  20.06   Red              M     0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "904a6d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Blue White</th>\n",
       "      <th>Color_Blue white</th>\n",
       "      <th>Color_Blue-White</th>\n",
       "      <th>Color_Blue-white</th>\n",
       "      <th>Color_Orange</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_yellow-white</th>\n",
       "      <th>Color_yellowish</th>\n",
       "      <th>Spectral_Class_A</th>\n",
       "      <th>Spectral_Class_B</th>\n",
       "      <th>Spectral_Class_F</th>\n",
       "      <th>Spectral_Class_G</th>\n",
       "      <th>Spectral_Class_K</th>\n",
       "      <th>Spectral_Class_M</th>\n",
       "      <th>Spectral_Class_O</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature         L       R    A_M  Color_Blue  Color_Blue White  \\\n",
       "0         3068  0.002400  0.1700  16.12           0                 0   \n",
       "1         3042  0.000500  0.1542  16.60           0                 0   \n",
       "2         2600  0.000300  0.1020  18.70           0                 0   \n",
       "3         2800  0.000200  0.1600  16.65           0                 0   \n",
       "4         1939  0.000138  0.1030  20.06           0                 0   \n",
       "\n",
       "   Color_Blue white  Color_Blue-White  Color_Blue-white  Color_Orange  ...  \\\n",
       "0                 0                 0                 0             0  ...   \n",
       "1                 0                 0                 0             0  ...   \n",
       "2                 0                 0                 0             0  ...   \n",
       "3                 0                 0                 0             0  ...   \n",
       "4                 0                 0                 0             0  ...   \n",
       "\n",
       "   Color_yellow-white  Color_yellowish  Spectral_Class_A  Spectral_Class_B  \\\n",
       "0                   0                0                 0                 0   \n",
       "1                   0                0                 0                 0   \n",
       "2                   0                0                 0                 0   \n",
       "3                   0                0                 0                 0   \n",
       "4                   0                0                 0                 0   \n",
       "\n",
       "   Spectral_Class_F  Spectral_Class_G  Spectral_Class_K  Spectral_Class_M  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 1   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 0                 0                 0                 1   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   Spectral_Class_O  Type  \n",
       "0                 0     0  \n",
       "1                 0     0  \n",
       "2                 0     0  \n",
       "3                 0     0  \n",
       "4                 0     0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a decision tree/ random forest can work with both categorical variables, such as color, as well\n",
    "# numerical attributes, but we will need to alter our categorical attributes before passing data\n",
    "# into a model. \n",
    "\n",
    "# for color, one of our categorical variables, we will use one hot encoding, as there is no\n",
    "# inherent or ordinal relationship between the colors (one color is not greater than another). We\n",
    "# will just do the same for spectral class as well.\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Color', 'Spectral_Class'], dtype=int)\n",
    "\n",
    "# Move the \"Type\" column to the end\n",
    "type_column = df.pop(\"Type\")\n",
    "df[\"Type\"] = type_column\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling is not necessary in decision tree, because we will locate the splits that give the best\n",
    "# reduction in entropy/ most information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9ae66",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f9ff95e",
   "metadata": {},
   "source": [
    "Knowing and understanding the way a decision tree works, our decision tree from scratch will consist of the following parts:\n",
    "\n",
    "- Node class: represents a node of the decision tree. Each node will have attributes like a split dimension (what attribute this node was split with), split point (what value of that split dimension was setteled on), and a label (which would give the class prediction if the node is a leaf), etc.\n",
    "\n",
    "- Entropy Computation: compute the entropy of a set of labels\n",
    "\n",
    "- Split Information: compute split information for a specific split point\n",
    "\n",
    "- Fitting the Tree: builds the desision tree model recursively \n",
    "\n",
    "- Classify: uses built model to predict labels of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aad294d",
   "metadata": {},
   "source": [
    "### Decision Tree from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0736abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_dim=None, split_point=None, label=None):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_point = split_point\n",
    "        self.label = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.label is not None\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    # computes the information (entropy) \n",
    "    def compute_info(self, labels: pd.Series) -> float:\n",
    "        total_samples = len(labels)\n",
    "        label_counts = labels.value_counts()\n",
    "        info = 0.0\n",
    "\n",
    "        # this is the key line: information is the negative sum of the probablity of each class times \n",
    "        # the log of that same probablity value for each class\n",
    "        for count in label_counts.values:\n",
    "            probability = count / total_samples\n",
    "            info -= probability * math.log2(probability)\n",
    "\n",
    "        return info\n",
    "\n",
    "    def split_info(self, data: pd.DataFrame, label: pd.Series, split_dim: int, split_point: float) -> float:\n",
    "        # left and right just represent the two subsets that are created when we split the data. We can \n",
    "        # capture the data that is in each subset, as well as the labels\n",
    "        data_left = data[data.iloc[:, split_dim] <= split_point]\n",
    "        data_right = data[data.iloc[:, split_dim] > split_point]\n",
    "        label_left = label[data.iloc[:, split_dim] <= split_point]\n",
    "        label_right = label[data.iloc[:, split_dim] > split_point]\n",
    "        # within this code, we are checking each value of the input value against the split point to \n",
    "        # decide if it goes to the left or right subset\n",
    "\n",
    "        total_samples = len(data)\n",
    "        total_left = len(data_left)\n",
    "        total_right = len(data_right)\n",
    "\n",
    "        p_left = total_left / total_samples\n",
    "        p_right = total_right / total_samples\n",
    "\n",
    "        info_left = self.compute_info(label_left)\n",
    "        info_right = self.compute_info(label_right)\n",
    "        # we then weigh the information we gather from each side's split, and return the sum of those \n",
    "        # as info_a\n",
    "        info_a = (p_left * info_left) + (p_right * info_right)\n",
    "\n",
    "        return info_a\n",
    "\n",
    "#_______________________________________________________________________________________________\n",
    "    def _split_data(self, data: pd.DataFrame, labels: pd.Series, split_dim: int, split_point: float) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "        data_left = data[data.iloc[:, split_dim] <= split_point]\n",
    "        data_right = data[data.iloc[:, split_dim] > split_point]\n",
    "        labels_left = labels[data.iloc[:, split_dim] <= split_point]\n",
    "        labels_right = labels[data.iloc[:, split_dim] > split_point]\n",
    "\n",
    "        return data_left, labels_left, data_right, labels_right\n",
    "\n",
    "    def _calculate_info_gain(self, data: pd.DataFrame, labels: pd.Series, split_dim: int, split_point: float) -> float:\n",
    "        total_samples = len(data)\n",
    "        total_left, total_right = 0, 0\n",
    "        count_left, count_right = labels[data.iloc[:, split_dim] <= split_point].value_counts(), labels[data.iloc[:, split_dim] > split_point].value_counts()\n",
    "\n",
    "        info = self.compute_info(labels)\n",
    "        info_left = 0.0\n",
    "        info_right = 0.0\n",
    "\n",
    "        for count in count_left.values:\n",
    "            probability = count / total_samples\n",
    "            info_left -= probability * math.log2(probability)\n",
    "\n",
    "        for count in count_right.values:\n",
    "            probability = count / total_samples\n",
    "            info_right -= probability * math.log2(probability)\n",
    "\n",
    "        info_gain = info - ((count_left.sum() / total_samples) * info_left + (count_right.sum() / total_samples) * info_right)\n",
    "        return info_gain\n",
    "    \n",
    "    def fit(self, train_data: pd.DataFrame, train_label: pd.Series) -> None:\n",
    "        self.root = self._recursive_build(train_data, train_label)\n",
    "\n",
    "    def _recursive_build(self, data: pd.DataFrame, labels: pd.Series, depth: int = 1) -> Node:\n",
    "        label_counts = labels.value_counts()\n",
    "        majority_label = label_counts.idxmax()\n",
    "\n",
    "        if len(label_counts) == 1 or depth > 2:\n",
    "            return Node(label=majority_label, split_dim=-1, split_point=-1.0)\n",
    "\n",
    "        num_features = data.shape[1]\n",
    "        best_info_gain = float('-inf')\n",
    "        best_split_dim = -1\n",
    "        best_split_point = -1\n",
    "\n",
    "        for split_dim in range(num_features):\n",
    "            split_points = self._calculate_split_points(data, split_dim)\n",
    "\n",
    "            for split_point in split_points:\n",
    "                info_gain = self._calculate_info_gain(data, labels, split_dim, split_point)\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_split_dim = split_dim\n",
    "                    best_split_point = split_point\n",
    "\n",
    "        node = Node(split_dim=best_split_dim, split_point=best_split_point, label=majority_label)\n",
    "\n",
    "        data_left, labels_left, data_right, labels_right = self._split_data(data, labels, best_split_dim, best_split_point)\n",
    "        if not data_left.empty and not data_right.empty:\n",
    "            node.left = self._recursive_build(data_left, labels_left, depth=depth + 1)\n",
    "            node.right = self._recursive_build(data_right, labels_right, depth=depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _calculate_split_points(self, data: pd.DataFrame, split_dim: int) -> List[float]:\n",
    "        attribute_values = sorted(data.iloc[:, split_dim].unique())\n",
    "        split_points = [(attribute_values[i] + attribute_values[i + 1]) / 2 for i in range(len(attribute_values) - 1)]\n",
    "        return split_points\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "    def classify(self, train_data: List[List[float]], train_label: List[int], test_data: List[List[float]]) -> List[int]:\n",
    "        self.fit(train_data, train_label)\n",
    "        predictions = []\n",
    "\n",
    "        for data_point in test_data:\n",
    "            predicted_label = self._traverse_tree(data_point, self.root)\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def _traverse_tree(self, data_point: List[float], node: Node) -> int:\n",
    "        if node.left is None and node.right is None:\n",
    "            return node.label\n",
    "        if data_point[node.split_dim] <= node.split_point:\n",
    "            return self._traverse_tree(data_point, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(data_point, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c54f3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32229779040910983\n"
     ]
    }
   ],
   "source": [
    "# Testing for Entropy and Split Info\n",
    "\n",
    "def parse_input_dataframe(df):\n",
    "    split_dim = 3  # Set the split_dim (dimension to split on) to 0 as an example\n",
    "    split_point = 13  # Set the split_point to 0.5 as an example\n",
    "\n",
    "    data = df.iloc[:15]  # Take the first 20 records and convert them to a list of lists\n",
    "    labels = df.iloc[:15]['Type']  # Extract the 'Type' column as the labels\n",
    "\n",
    "    return data, labels, split_dim, split_point\n",
    "\n",
    "data, labels, split_dim, split_point = parse_input_dataframe(df)\n",
    "\n",
    "solution = Solution()\n",
    "\n",
    "# Call the split_info method with the parsed data\n",
    "result = solution.split_info(data, labels, split_dim, split_point)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a498611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{split_dim: 3, split_point: 15.42, label: 0}{{split_dim: -1, split_point: -1.0, label: 1}}{{split_dim: -1, split_point: -1.0, label: 0}}\n",
      "\n",
      "{{split_dim: -1, split_point: -1.0, label: 1}}{split_dim: 3, split_point: 15.42, label: 0}{{split_dim: -1, split_point: -1.0, label: 0}}\n"
     ]
    }
   ],
   "source": [
    "# Testing for the tree creation and fit\n",
    "\n",
    "dataset = df.iloc[:20, :-1]\n",
    "labels = df.iloc[:20, -1]\n",
    "\n",
    "# Create an instance of the Solution class\n",
    "solution = Solution()\n",
    "\n",
    "# Build the decision tree using the fit function\n",
    "solution.fit(dataset, labels)\n",
    "\n",
    "def preorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + preorder_traversal(node.left) + \"}\"\n",
    "        result += \"{\" + preorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "def inorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.left) + \"}\"\n",
    "    result += \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "# Perform preorder traversal on the decision tree\n",
    "preorder_result = preorder_traversal(solution.root)\n",
    "print(preorder_result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Perform inorder traversal on the decision tree\n",
    "inorder_result = inorder_traversal(solution.root)\n",
    "print(inorder_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe90a25",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Information Gain and Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a2c86",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Building the Tree and Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd8127",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pruning and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fecaa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10145329",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Forest as an Ensemble of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33faaaff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Subspace Method for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd31149",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bootstrapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b6a96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff4dea",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation of Models and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b325d0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variations and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54db96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Feature Importance Estimation with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17373fa2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Handling Missing Data and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edb49c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extending Random Forest to Handle Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45514f56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Multiclass Classification and Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f75f0c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Coursework for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b952ac0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Classification Test\n",
    "\n",
    "def parse_classification_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        test_data = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            parts = line.split()\n",
    "            label = int(parts[0])\n",
    "            attributes = [float(attr.split(':')[1]) for attr in parts[1:]]\n",
    "            \n",
    "            if label != -1:\n",
    "                train_data.append(attributes)\n",
    "                train_label.append(label)\n",
    "            else:\n",
    "                test_data.append(attributes)\n",
    "    \n",
    "    return train_data, train_label, test_data\n",
    "\n",
    "input_file = r\"C:\\Users\\rogerree\\Downloads\\01mSTLanT0igEUUS8kDmDQ_2834ea673e8949dea706a3da771f23f1_PA-DT-Handout\\dt_handout\\sample_test_cases\\classification\\input01.txt\"\n",
    "train_data, train_label, test_data = parse_classification_data(input_file)\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "solution = Solution()\n",
    "\n",
    "\n",
    "# Call the classify method with the extracted data\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b30f7a7eb703ca28cacee6ec948cc633c111373f841ced60a7b8e477f4c2a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
