{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d89b5c",
   "metadata": {},
   "source": [
    "# Random Forest from Scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d944ef2",
   "metadata": {},
   "source": [
    "In this notebook, I will be entirely covering topics relating to the Random Forest Algorithm. This will start with a simple decision tree implementation, and go over various topics. The dataset that will be used is a NASA star type classfication dataset, where the goal is to have our tree predict the correct star classification given its tree of rules. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd7a2a63",
   "metadata": {},
   "source": [
    "## Importing and Prepping Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59c2054b",
   "metadata": {},
   "source": [
    "Temperature -- K <br>\n",
    "L -- L/Lo<br>\n",
    "R -- R/Ro<br>\n",
    "AM -- Mv<br>\n",
    "Color -- General Color of Spectrum<br>\n",
    "Spectral_Class -- O,B,A,F,G,K,M / SMASS - https://en.wikipedia.org/wiki/Asteroid_spectral_types<br>\n",
    "Type -- Red Dwarf, Brown Dwarf, White Dwarf, Main Sequence , Super Giants, Hyper Giants<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978a9db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrogerree\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive - Merck Sharp & Dohme LLC\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPersonal Projects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mStars.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\rogerree\\\\OneDrive - Merck Sharp & Dohme LLC\\\\Documents\\\\Personal Projects\\\\Data\\\\Stars.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "156961ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temperature         int64\n",
       "L                 float64\n",
       "R                 float64\n",
       "A_M               float64\n",
       "Color              object\n",
       "Spectral_Class     object\n",
       "Type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "23ca242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spectral_Class</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature         L       R    A_M Color Spectral_Class  Type\n",
       "0         3068  0.002400  0.1700  16.12   Red              M     0\n",
       "1         3042  0.000500  0.1542  16.60   Red              M     0\n",
       "2         2600  0.000300  0.1020  18.70   Red              M     0\n",
       "3         2800  0.000200  0.1600  16.65   Red              M     0\n",
       "4         1939  0.000138  0.1030  20.06   Red              M     0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "904a6d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Blue White</th>\n",
       "      <th>Color_Blue white</th>\n",
       "      <th>Color_Blue-White</th>\n",
       "      <th>Color_Blue-white</th>\n",
       "      <th>Color_Orange</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_yellow-white</th>\n",
       "      <th>Color_yellowish</th>\n",
       "      <th>Spectral_Class_A</th>\n",
       "      <th>Spectral_Class_B</th>\n",
       "      <th>Spectral_Class_F</th>\n",
       "      <th>Spectral_Class_G</th>\n",
       "      <th>Spectral_Class_K</th>\n",
       "      <th>Spectral_Class_M</th>\n",
       "      <th>Spectral_Class_O</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3042</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>16.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1939</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>20.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature         L       R    A_M  Color_Blue  Color_Blue White  \\\n",
       "0         3068  0.002400  0.1700  16.12           0                 0   \n",
       "1         3042  0.000500  0.1542  16.60           0                 0   \n",
       "2         2600  0.000300  0.1020  18.70           0                 0   \n",
       "3         2800  0.000200  0.1600  16.65           0                 0   \n",
       "4         1939  0.000138  0.1030  20.06           0                 0   \n",
       "\n",
       "   Color_Blue white  Color_Blue-White  Color_Blue-white  Color_Orange  ...  \\\n",
       "0                 0                 0                 0             0  ...   \n",
       "1                 0                 0                 0             0  ...   \n",
       "2                 0                 0                 0             0  ...   \n",
       "3                 0                 0                 0             0  ...   \n",
       "4                 0                 0                 0             0  ...   \n",
       "\n",
       "   Color_yellow-white  Color_yellowish  Spectral_Class_A  Spectral_Class_B  \\\n",
       "0                   0                0                 0                 0   \n",
       "1                   0                0                 0                 0   \n",
       "2                   0                0                 0                 0   \n",
       "3                   0                0                 0                 0   \n",
       "4                   0                0                 0                 0   \n",
       "\n",
       "   Spectral_Class_F  Spectral_Class_G  Spectral_Class_K  Spectral_Class_M  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 1   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 0                 0                 0                 1   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   Spectral_Class_O  Type  \n",
       "0                 0     0  \n",
       "1                 0     0  \n",
       "2                 0     0  \n",
       "3                 0     0  \n",
       "4                 0     0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a decision tree/ random forest can work with both categorical variables, such as color, as well\n",
    "# numerical attributes, but we will need to alter our categorical attributes before passing data\n",
    "# into a model. \n",
    "\n",
    "# for color, one of our categorical variables, we will use one hot encoding, as there is no\n",
    "# inherent or ordinal relationship between the colors (one color is not greater than another). We\n",
    "# will just do the same for spectral class as well.\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Color', 'Spectral_Class'], dtype=int)\n",
    "\n",
    "# Move the \"Type\" column to the end\n",
    "type_column = df.pop(\"Type\")\n",
    "df[\"Type\"] = type_column\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "789483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling is not necessary in decision tree, because we will locate the splits that give the best\n",
    "# reduction in entropy/ most information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9ae66",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f9ff95e",
   "metadata": {},
   "source": [
    "Knowing and understanding the way a decision tree works, our decision tree from scratch will consist of the following parts:\n",
    "\n",
    "- Node class: represents a node of the decision tree. Each node will have attributes like a split dimension (what attribute this node was split with), split point (what value of that split dimension was setteled on), and a label (which would give the class prediction if the node is a leaf), etc.\n",
    "\n",
    "- Entropy Computation: compute the entropy of a set of labels\n",
    "\n",
    "- Split Information: compute split information for a specific split point\n",
    "\n",
    "- Fitting the Tree: builds the desision tree model recursively \n",
    "\n",
    "- Classify: uses built model to predict labels of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aad294d",
   "metadata": {},
   "source": [
    "### Decision Tree from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0736abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_dim=None, split_point=None, label=None):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_point = split_point\n",
    "        self.label = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.label is not None\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    # computes the information (entropy) \n",
    "    def compute_info(self, labels: pd.Series) -> float:\n",
    "        total_samples = len(labels)\n",
    "        label_counts = labels.value_counts()\n",
    "        info = 0.0\n",
    "\n",
    "        # this is the key line: information is the negative sum of the probablity of each class times \n",
    "        # the log of that same probablity value for each class\n",
    "        for count in label_counts.values:\n",
    "            probability = count / total_samples\n",
    "            info -= probability * math.log2(probability)\n",
    "\n",
    "        return info\n",
    "\n",
    "    # grabs two subsets and tells us how valuable a split point is based on entropy\n",
    "    def split_info(self, data: pd.DataFrame, label: pd.Series, split_dim: int, split_point: float) -> float:\n",
    "        data_left, label_left, data_right, label_right = self._split_data(data, label, split_dim, split_point)\n",
    "\n",
    "        total_samples = len(data)\n",
    "        total_left = len(data_left)\n",
    "        total_right = len(data_right)\n",
    "\n",
    "        p_left = total_left / total_samples\n",
    "        p_right = total_right / total_samples\n",
    "\n",
    "        info_left = self.compute_info(label_left)\n",
    "        info_right = self.compute_info(label_right)\n",
    "        # we then weigh the information we gather from each side's split, and return the sum of those \n",
    "        # as info_a\n",
    "        info_a = (p_left * info_left) + (p_right * info_right)\n",
    "\n",
    "        return info_a\n",
    "\n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "    # this is needed to actually split the data. We need to split in the recursive build, so we can define this behavior and also use it in split_info\n",
    "    def _split_data(self, data: pd.DataFrame, labels: pd.Series, split_dim: int, split_point: float) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "\n",
    "        # left and right just represent the two subsets that are created when we split the data. We can \n",
    "        # capture the data that is in each subset, as well as the labels\n",
    "        data_left = data[data.iloc[:, split_dim] <= split_point]\n",
    "        data_right = data[data.iloc[:, split_dim] > split_point]\n",
    "        labels_left = labels[data.iloc[:, split_dim] <= split_point]\n",
    "        labels_right = labels[data.iloc[:, split_dim] > split_point]\n",
    "\n",
    "        return data_left, labels_left, data_right, labels_right\n",
    "    \n",
    "    # used to get information gain, which differs from split info\n",
    "    def _calculate_info_gain(self, data: pd.DataFrame, labels: pd.Series, split_dim: int, split_point: float) -> float:\n",
    "        total_samples = len(data)\n",
    "        total_left, total_right = 0, 0\n",
    "        count_left, count_right = {}, {}\n",
    "\n",
    "        for i in range(total_samples):\n",
    "            if data.iloc[i, split_dim] <= split_point:\n",
    "                total_left += 1\n",
    "                label = labels.iloc[i]\n",
    "                if label in count_left:\n",
    "                    count_left[label] += 1\n",
    "                else:\n",
    "                    count_left[label] = 1\n",
    "            else:\n",
    "                total_right += 1\n",
    "                label = labels.iloc[i]\n",
    "                if label in count_right:\n",
    "                    count_right[label] += 1\n",
    "                else:\n",
    "                    count_right[label] = 1\n",
    "\n",
    "        info = self.compute_info(labels)\n",
    "        info_left = 0.0\n",
    "        info_right = 0.0\n",
    "\n",
    "        for count in count_left.values():\n",
    "            probability = count / total_left\n",
    "            info_left -= probability * math.log2(probability)\n",
    "\n",
    "        for count in count_right.values():\n",
    "            probability = count / total_right\n",
    "            info_right -= probability * math.log2(probability)\n",
    "\n",
    "        info_gain = info - ((total_left / total_samples) * info_left + (total_right / total_samples) * info_right)\n",
    "        return info_gain\n",
    "    \n",
    "    # fit just calls recursive build\n",
    "    def fit(self, train_data: pd.DataFrame, train_label: pd.Series) -> None:\n",
    "        self.root = self._recursive_build(train_data, train_label)\n",
    "\n",
    "    # builds the tree\n",
    "    def _recursive_build(self, data: pd.DataFrame, labels: pd.Series, depth: int = 1) -> Node:\n",
    "        label_counts = labels.value_counts()\n",
    "        majority_label = label_counts.idxmax()\n",
    "        \n",
    "        # our stopping criteri; if the subset is all one label (leaf node) or the depth reaches more than 2, we return the node\n",
    "        if len(label_counts) == 1 or depth > 2:\n",
    "            return Node(label=majority_label, split_dim=-1, split_point=-1.0)\n",
    "\n",
    "        num_features = data.shape[1]\n",
    "        best_info_gain = float('-inf')\n",
    "        best_split_dim = -1\n",
    "        best_split_point = -1\n",
    "\n",
    "        # find best information gain among split dimensions and split points\n",
    "        for split_dim in range(num_features):\n",
    "            split_points = self._calculate_split_points(data, split_dim)\n",
    "            for split_point in split_points:\n",
    "                info_gain = self._calculate_info_gain(data, labels, split_dim, split_point)\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_split_dim = split_dim\n",
    "                    best_split_point = split_point\n",
    "\n",
    "        # set the node's properties to the split dimension, split point and label we found\n",
    "        node = Node(split_dim=best_split_dim, split_point=best_split_point, label=majority_label)\n",
    "\n",
    "        # now split again\n",
    "        data_left, labels_left, data_right, labels_right = self._split_data(data, labels, best_split_dim, best_split_point)\n",
    "\n",
    "        # if we are not at a leaf node, then call recursive build again\n",
    "        if not data_left.empty and not data_right.empty:\n",
    "            node.left = self._recursive_build(data_left, labels_left, depth=depth + 1)\n",
    "            node.right = self._recursive_build(data_right, labels_right, depth=depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    # needed in order to calculate the potential split points. Takes in the data and a split dimension\n",
    "    def _calculate_split_points(self, data: pd.DataFrame, split_dim: int) -> List[float]:\n",
    "\n",
    "        # gets unique values from selected dimension and sorts them in ascending order\n",
    "        attribute_values = sorted(data.iloc[:, split_dim])\n",
    "\n",
    "        # grabs all midpoints between each adjacent pair of values from our dimension\n",
    "        split_points = [(attribute_values[i] + attribute_values[i + 1]) / 2 for i in range(len(attribute_values) - 1)]\n",
    "\n",
    "        # returns the list of all split points\n",
    "        return split_points\n",
    "    \n",
    "#_______________________________________________________________________________________________\n",
    "\n",
    "    # here we look into our tree we built and select the node label\n",
    "    def classify(self, train_data: pd.DataFrame, train_label: pd.Series, test_data: pd.DataFrame) -> List[int]:\n",
    "        self.fit(train_data, train_label)\n",
    "        predictions = []\n",
    "\n",
    "        # for each data point in the test data, set the predicted label to the value derived by traversing the tree\n",
    "        for _, data_point in test_data.iterrows():\n",
    "            predicted_label = self._traverse_tree(data_point, self.root)\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # look into the tree\n",
    "    def _traverse_tree(self, data_point: pd.Series, node: Node) -> int:\n",
    "        # if we are at leaf node, return the label\n",
    "        if node.left is None and node.right is None:\n",
    "            return node.label\n",
    "        # if the value of the given data point (and split dimension) is less, go to the left\n",
    "        if data_point[node.split_dim] <= node.split_point:\n",
    "            return self._traverse_tree(data_point, node.left)\n",
    "        else:\n",
    "            # else, go right and call traverse again\n",
    "            return self._traverse_tree(data_point, node.right)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "746625db",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c54f3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "# Testing for Entropy and Split Info\n",
    "\n",
    "def parse_input_dataframe(df):\n",
    "    split_dim = 2  # Set the split_dim (dimension to split on) to 0 as an example\n",
    "    split_point = 13  # Set the split_point to 0.5 as an example\n",
    "\n",
    "    data = df.iloc[:15]  # Take the first 20 records and convert them to a list of lists\n",
    "    labels = df.iloc[:15]['Type']  # Extract the 'Type' column as the labels\n",
    "\n",
    "    return data, labels, split_dim, split_point\n",
    "\n",
    "data, labels, split_dim, split_point = parse_input_dataframe(df)\n",
    "\n",
    "solution = Solution()\n",
    "\n",
    "# Call the split_info method with the parsed data\n",
    "result = solution.split_info(data, labels, split_dim, split_point)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9a498611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{split_dim: 1, split_point: 0.07050000000000001, label: 0}{{split_dim: 0, split_point: 5396.0, label: 0}{{split_dim: -1, split_point: -1.0, label: 0}}{{split_dim: -1, split_point: -1.0, label: 2}}}{{split_dim: 2, split_point: 11.3, label: 3}{{split_dim: -1, split_point: -1.0, label: 3}}{{split_dim: -1, split_point: -1.0, label: 4}}}\n",
      "\n",
      "{{{split_dim: -1, split_point: -1.0, label: 0}}{split_dim: 0, split_point: 5396.0, label: 0}{{split_dim: -1, split_point: -1.0, label: 2}}}{split_dim: 1, split_point: 0.07050000000000001, label: 0}{{{split_dim: -1, split_point: -1.0, label: 3}}{split_dim: 2, split_point: 11.3, label: 3}{{split_dim: -1, split_point: -1.0, label: 4}}}\n"
     ]
    }
   ],
   "source": [
    "# Testing for the tree creation and fit\n",
    "\n",
    "dataset = df.iloc[:1000, :-1]\n",
    "labels = df.iloc[:1000, -1]\n",
    "\n",
    "# Create an instance of the Solution class\n",
    "solution = Solution()\n",
    "\n",
    "# Build the decision tree using the fit function\n",
    "solution.fit(dataset, labels)\n",
    "\n",
    "def preorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + preorder_traversal(node.left) + \"}\"\n",
    "        result += \"{\" + preorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "def inorder_traversal(node):\n",
    "    if node is None:\n",
    "        return \"\"\n",
    "    result = \"\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.left) + \"}\"\n",
    "    result += \"{\" + f\"split_dim: {node.split_dim}, split_point: {node.split_point}, label: {node.label}\" + \"}\"\n",
    "    if node.left or node.right:\n",
    "        result += \"{\" + inorder_traversal(node.right) + \"}\"\n",
    "    return result\n",
    "\n",
    "# Perform preorder traversal on the decision tree\n",
    "preorder_result = preorder_traversal(solution.root)\n",
    "print(preorder_result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Perform inorder traversal on the decision tree\n",
    "inorder_result = inorder_traversal(solution.root)\n",
    "print(inorder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "46906919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{split_dim: 1, split_point: 1.0, label: 1}{{split_dim: -1, split_point: -1.0, label: 1}}{{split_dim: 0, split_point: 1.5, label: 3}{{split_dim: -1, split_point: -1.0, label: 1}}{{split_dim: -1, split_point: -1.0, label: 3}}}\n"
     ]
    }
   ],
   "source": [
    "# another test for structure\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    ['1', '1.0', '1.0'],\n",
    "    ['1', '1.0', '2.0'],\n",
    "    ['1', '2.0', '1.0'],\n",
    "    ['3', '2.0', '2.0'],\n",
    "    ['1', '3.0', '1.0'],\n",
    "    ['3', '3.0', '2.0'],\n",
    "    ['3', '3.0', '3.0'],\n",
    "    ['3', '4.5', '3.0']\n",
    "]\n",
    "\n",
    "# Creating the DataFrame\n",
    "#df = pd.DataFrame(data, columns=['label', 'attribute 0', 'attribute 1'])\n",
    "\n",
    "# testing\n",
    "\n",
    "classifier = Solution()\n",
    "\n",
    "train_data = df[df['label'] != '-1'].drop('label', axis=1).astype(float)\n",
    "train_label = df[df['label'] != '-1']['label'].astype(int)\n",
    "test_data = df[df['label'] == '-1'].drop('label', axis=1).astype(float)\n",
    "\n",
    "predictions = classifier.classify(train_data, train_label, test_data)\n",
    "\n",
    "# Perform preorder traversal on the decision tree\n",
    "preorder_result = preorder_traversal(classifier.root)\n",
    "print(preorder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1a3193ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "{split_dim: 1, split_point: 1.0, label: 1}{{split_dim: -1, split_point: -1.0, label: 1}}{{split_dim: 0, split_point: 1.5, label: 3}{{split_dim: -1, split_point: -1.0, label: 1}}{{split_dim: -1, split_point: -1.0, label: 3}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the traversal of the tree and classification\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    ['1', '1.0', '1.0'],\n",
    "    ['1', '1.0', '2.0'],\n",
    "    ['1', '2.0', '1.0'],\n",
    "    ['3', '2.0', '2.0'],\n",
    "    ['1', '3.0', '1.0'],\n",
    "    ['3', '3.0', '2.0'],\n",
    "    ['3', '3.0', '3.0'],\n",
    "    ['3', '4.5', '3.0'],\n",
    "    ['-1', '1.0', '2.2'],\n",
    "    ['-1', '4.5', '1.0']\n",
    "]\n",
    "\n",
    "# Creating the DataFrame\n",
    "#df = pd.DataFrame(data, columns=['label', 'attribute 0', 'attribute 1'])\n",
    "\n",
    "# testing\n",
    "\n",
    "classifier = Solution()\n",
    "\n",
    "train_data = df[df['label'] != '-1'].drop('label', axis=1).astype(float)\n",
    "train_label = df[df['label'] != '-1']['label'].astype(int)\n",
    "test_data = df[df['label'] == '-1'].drop('label', axis=1).astype(float)\n",
    "\n",
    "predictions = classifier.classify(train_data, train_label, test_data)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "preorder_result = preorder_traversal(classifier.root)\n",
    "print(preorder_result)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "648e39cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{split_dim: 1, split_point: 2.076767332959929, label: 3}{{split_dim: 2, split_point: 2.0413842935532105, label: 2}{{split_dim: -1, split_point: -1.0, label: 2}}{{split_dim: -1, split_point: -1.0, label: 2}}}{{split_dim: 2, split_point: 3.041219385179334, label: 3}{{split_dim: -1, split_point: -1.0, label: 3}}{{split_dim: -1, split_point: -1.0, label: 2}}}\n",
      "\n",
      "[2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the text file\n",
    "with open(r\"C:\\Users\\rogerree\\OneDrive - Merck Sharp & Dohme LLC\\Desktop\\input01.txt\", \"r\") as file:\n",
    "    lines = file.read().splitlines()\n",
    "\n",
    "# Convert the data into a list of lists\n",
    "data = [line.split() for line in lines]\n",
    "\n",
    "# Extract the label and remove the attribute prefixes from the data\n",
    "data = [[row[0]] + [value.split(\":\")[1] for value in row[1:] if \":\" in value] for row in data]\n",
    "\n",
    "# Filter out rows with no values after removing prefixes\n",
    "data = [row for row in data if len(row) > 1]\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "classifier = Solution()\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df.columns = ['label'] + [f'attr_{i}' for i in range(1, len(df.columns))]\n",
    "\n",
    "# Split the data into train and test\n",
    "train_data = df[df['label'] != '-1'].drop('label', axis=1).astype(float)\n",
    "train_label = df[df['label'] != '-1']['label'].astype(int)\n",
    "test_data = df[df['label'] == '-1'].drop('label', axis=1).astype(float)\n",
    "\n",
    "# Classify using the test data\n",
    "predictions = classifier.classify(train_data, train_label, test_data)\n",
    "# Perform preorder traversal on the decision tree\n",
    "preorder_result = preorder_traversal(classifier.root)\n",
    "print(preorder_result)\n",
    "print()\n",
    "print(predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e860cee1",
   "metadata": {},
   "source": [
    "### Evaluation of Model and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "28fc796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "# first, with a basic 20/80 test train split \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test DataFrames (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# setting training/ testing data and labels (as df's)\n",
    "test_data = test_df.iloc[:test_df.shape[0], :-1]\n",
    "test_labels = test_df.iloc[:test_df.shape[0], -1]\n",
    "\n",
    "train_data = train_df.iloc[:train_df.shape[0], :-1]\n",
    "train_labels = train_df.iloc[:train_df.shape[0], -1]\n",
    "\n",
    "# Instantiating and training the decision tree model\n",
    "model = Solution()\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "# Generating predictions on the test set\n",
    "predictions = model.classify(train_data, train_labels, test_data)\n",
    "\n",
    "# Calculating accuracy metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "# Printing the accuracy metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d8f98",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd8127",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pruning and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fecaa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10145329",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Forest as an Ensemble of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33faaaff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Random Subspace Method for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd31149",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bootstrapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b6a96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff4dea",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation of Models and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b325d0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variations and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54db96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Feature Importance Estimation with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17373fa2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Handling Missing Data and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edb49c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extending Random Forest to Handle Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45514f56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Multiclass Classification and Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f75f0c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Coursework for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b952ac0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Classification Test\n",
    "\n",
    "def parse_classification_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        test_data = []\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            parts = line.split()\n",
    "            label = int(parts[0])\n",
    "            attributes = [float(attr.split(':')[1]) for attr in parts[1:]]\n",
    "            \n",
    "            if label != -1:\n",
    "                train_data.append(attributes)\n",
    "                train_label.append(label)\n",
    "            else:\n",
    "                test_data.append(attributes)\n",
    "    \n",
    "    return train_data, train_label, test_data\n",
    "\n",
    "input_file = r\"C:\\Users\\rogerree\\Downloads\\01mSTLanT0igEUUS8kDmDQ_2834ea673e8949dea706a3da771f23f1_PA-DT-Handout\\dt_handout\\sample_test_cases\\classification\\input01.txt\"\n",
    "train_data, train_label, test_data = parse_classification_data(input_file)\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "solution = Solution()\n",
    "\n",
    "\n",
    "# Call the classify method with the extracted data\n",
    "result = solution.classify(train_data, train_label, test_data)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b30f7a7eb703ca28cacee6ec948cc633c111373f841ced60a7b8e477f4c2a2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
